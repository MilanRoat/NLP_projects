{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# stock news sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 : News headline extraction of few selected companies from fiviz website"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### company_names = 'qualcomm','american express','morgan stanley','Deutsche Bank','Citigroup','bank of montreal','Barclays','bank of hawaii','Bank of america'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen,Request\n",
    "from bs4 import BeautifulSoup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finviz_url = \"https://finviz.com/quote.ashx?t=\"\n",
    "tickers = ['QCOM','AXP','MS','BCS','DB','C','BMO','BOH','BAC']\n",
    "\n",
    "news_tables = {}\n",
    "for ticker in tickers:\n",
    "    url = finviz_url + ticker\n",
    "\n",
    "    req = Request(url=url, headers={'user-agent': 'my-app'})\n",
    "    response = urlopen(req)\n",
    "\n",
    "    html = BeautifulSoup(response, features='html.parser')\n",
    "    news_table = html.find(id='news-table')\n",
    "    news_tables[ticker] = news_table\n",
    "\n",
    "parsed_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ticker, news_table in news_tables.items():\n",
    "    for row in news_table.findAll('tr'):\n",
    "        title = row.a.text.strip()\n",
    "        date_time_text = row.td.text.strip()\n",
    "        \n",
    "        # Initialize date and time variables\n",
    "        date = ''\n",
    "        time = ''\n",
    "        \n",
    "        if ' ' in date_time_text:  # Both date and time are present\n",
    "            date, time = date_time_text.split(' ', 1)\n",
    "        else:  # Only time is present\n",
    "            time = date_time_text\n",
    "\n",
    "        parsed_data.append([ticker, date, time, title])\n",
    "\n",
    "df3 = pd.DataFrame(parsed_data, columns=['ticker', 'date', 'time', 'title'])\n",
    "\n",
    "\n",
    "def convert_date_format(date_str):\n",
    "    try:\n",
    "       \n",
    "        date = pd.to_datetime(date_str, format='%b-%d-%y')\n",
    "        \n",
    "        return date.strftime('%d-%m-%Y')\n",
    "    except ValueError:\n",
    "        \n",
    "        return date_str\n",
    "\n",
    "\n",
    "df3['date'] = df3['date'].apply(convert_date_format)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ticker        date     time  \\\n",
      "0   QCOM  17-06-2024  09:34PM   \n",
      "1   QCOM  17-06-2024  05:06PM   \n",
      "\n",
      "                                               title  \n",
      "0  Qualcomm to benefit most from slow Samsung 3nm...  \n",
      "1  Is Qualcomm (NASDAQ:QCOM) the Best AI PC Stock...  \n"
     ]
    }
   ],
   "source": [
    "df3['date'] = df3['date'].replace('', pd.NA).ffill()\n",
    "df3['date'] = df3['date'].replace('Today','17-06-2024')\n",
    "# changing all dates from today to 17th june\n",
    "print(df3.head(2))\n",
    "df3.to_csv('raw_stock_news.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_n = pd.read_csv('raw_stock_news.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### selecting most important news from multiple news articles for a sepecific date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\hp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Unnamed: 0 ticker        date     time  \\\n",
      "0             0   QCOM  17-06-2024  09:34PM   \n",
      "1             1   QCOM  17-06-2024  05:06PM   \n",
      "2             2   QCOM  17-06-2024  04:57PM   \n",
      "3             3   QCOM  17-06-2024  04:51PM   \n",
      "4             4   QCOM  17-06-2024  02:44PM   \n",
      "..          ...    ...         ...      ...   \n",
      "895         895    BAC  04-06-2024  08:02AM   \n",
      "896         896    BAC  04-06-2024  06:15AM   \n",
      "897         897    BAC  03-06-2024  05:45PM   \n",
      "898         898    BAC  03-06-2024  05:06PM   \n",
      "899         899    BAC  03-06-2024  02:34PM   \n",
      "\n",
      "                                                 title  compound  \n",
      "0    Qualcomm to benefit most from slow Samsung 3nm...    0.4588  \n",
      "1    Is Qualcomm (NASDAQ:QCOM) the Best AI PC Stock...    0.6369  \n",
      "2    Nvidia Turbocharges Semiconductor ETFs Even As...    0.5994  \n",
      "3    Qualcomm reaches $75 million settlement over s...    0.0516  \n",
      "4    Stocks to Watch Tuesday: Qualcomm, Micron Tech...    0.2732  \n",
      "..                                                 ...       ...  \n",
      "895  GitLab Inc. (NASDAQ:GTLB) Q1 2025 Earnings Cal...    0.0000  \n",
      "896  3 Dividend Stocks That Even Ken Griffin Is Buying    0.0000  \n",
      "897  Bank of America (BAC) Stock Dips While Market ...    0.3400  \n",
      "898  S&P 500 Gains and Losses Today: Paramount Pops...   -0.0772  \n",
      "899  3 Stocks Billionaires Are Buying Instead of Nv...    0.0000  \n",
      "\n",
      "[900 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "vader = SentimentIntensityAnalyzer()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "f = lambda title: vader.polarity_scores(title)['compound']\n",
    "df_n['compound'] = df_n['title'].apply(f)\n",
    "\n",
    "print(df_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "138\n",
      "    ticker        date     time  \\\n",
      "0      AXP  03-06-2024  05:45PM   \n",
      "1      AXP  04-06-2024  06:45AM   \n",
      "2      AXP  05-06-2024  07:10AM   \n",
      "3      AXP  06-06-2024  06:36AM   \n",
      "4      AXP  07-06-2024  02:04PM   \n",
      "..     ...         ...      ...   \n",
      "273   QCOM  26-05-2024  04:03PM   \n",
      "274   QCOM  28-05-2024  06:22AM   \n",
      "275   QCOM  29-05-2024  09:11AM   \n",
      "276   QCOM  30-05-2024  06:43AM   \n",
      "277   QCOM  31-05-2024  01:38PM   \n",
      "\n",
      "                                                 title  compound  \n",
      "0    American Express (AXP) Stock Declines While Ma...    0.4215  \n",
      "1    3 Blue-Chip Stocks You'll Regret Not Buying in...   -0.4215  \n",
      "2      The 3 Best Blue-Chip Stocks to Buy in June 2024    0.6369  \n",
      "3    Hidden Treasures: 3 Dow Stocks That Deserve MU...    0.8062  \n",
      "4    American Express (AXP) Rises 36% in a Year: Mo...    0.0000  \n",
      "..                                                 ...       ...  \n",
      "273  10 Best AI Stocks to Buy for 2024 According to...    0.6369  \n",
      "274  If You Can Only Buy One Stock in May, It Bette...    0.4404  \n",
      "275  1 Soaring Artificial Intelligence (AI) Stock t...    0.7430  \n",
      "276  Is Taiwan Semiconductor (TSM) The Best AI Semi...    0.6369  \n",
      "277  Calls of the Day: Charles Schwab, Qualcomm and...    0.0000  \n",
      "\n",
      "[278 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_filtered = df_n.loc[df_n.groupby(['ticker', 'date'])['compound'].apply(lambda x: x.abs().idxmax())]\n",
    "\n",
    "\n",
    "df_filtered.reset_index(drop=True, inplace=True)\n",
    "\n",
    "\n",
    "print(df_filtered['Unnamed: 0'][0])\n",
    "df_filtered.drop('Unnamed: 0',axis=1,inplace=True)\n",
    "print(df_filtered)\n",
    "\n",
    "df_filtered.to_csv('M2_news_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data extraction of true stock values of selected companies in 2024 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From yahoo finance historical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "file_names = ['QCOM.csv','AXP.csv','MS.csv','DB.csv','C.csv','BMO.csv','BCS.csv','BOH.csv','BAC.csv']\n",
    "company_names = ['qualcomm','american express','morgan stanley','Deutsche Bank','Citigroup','bank of montreal','Barclays','bank of hawaii','Bank of america']\n",
    "\n",
    "def add_bullish_bearish_columns_and_combine(file_names, company_names, output_file, start_date='01-01-2024'):\n",
    "    combined_df = pd.DataFrame()\n",
    "    \n",
    "    for csv_file, company_name in zip(file_names, company_names):\n",
    "        \n",
    "        df = pd.read_csv(csv_file, parse_dates=['Date'], dayfirst=True)  ## day first true is for date format\n",
    "        \n",
    "        \n",
    "        df = df[df['Date'] >= pd.to_datetime(start_date, format='%d-%m-%Y')]\n",
    "        \n",
    "     \n",
    "        df['Bullish/Bearish'] = df.apply(lambda row: 'Bullish' if row['Close'] > row['Open'] else 'Bearish', axis=1)\n",
    "        df['ticker'] = csv_file.split('.')[0]\n",
    "        df['company_name'] = company_name\n",
    "        \n",
    "      \n",
    "        df['Date'] = df['Date'].dt.strftime('%d-%m-%Y')\n",
    "        \n",
    "        \n",
    "        combined_df = pd.concat([combined_df, df], ignore_index=True)\n",
    "    \n",
    "    \n",
    "    combined_df.to_csv(output_file, index=False)\n",
    "\n",
    "\n",
    "output_file = 'combined_stock_data.csv'\n",
    "add_bullish_bearish_columns_and_combine(file_names, company_names, output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Bullish/Bearish</th>\n",
       "      <th>ticker</th>\n",
       "      <th>company_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>02-01-2024</td>\n",
       "      <td>142.190002</td>\n",
       "      <td>142.199997</td>\n",
       "      <td>138.779999</td>\n",
       "      <td>140.229996</td>\n",
       "      <td>138.951874</td>\n",
       "      <td>8495800</td>\n",
       "      <td>Bearish</td>\n",
       "      <td>QCOM</td>\n",
       "      <td>qualcomm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>03-01-2024</td>\n",
       "      <td>138.889999</td>\n",
       "      <td>138.889999</td>\n",
       "      <td>136.990005</td>\n",
       "      <td>137.600006</td>\n",
       "      <td>136.345856</td>\n",
       "      <td>8133300</td>\n",
       "      <td>Bearish</td>\n",
       "      <td>QCOM</td>\n",
       "      <td>qualcomm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>04-01-2024</td>\n",
       "      <td>135.440002</td>\n",
       "      <td>137.330002</td>\n",
       "      <td>134.940002</td>\n",
       "      <td>136.169998</td>\n",
       "      <td>134.928879</td>\n",
       "      <td>6770300</td>\n",
       "      <td>Bullish</td>\n",
       "      <td>QCOM</td>\n",
       "      <td>qualcomm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>05-01-2024</td>\n",
       "      <td>136.160004</td>\n",
       "      <td>138.070007</td>\n",
       "      <td>135.850006</td>\n",
       "      <td>136.729996</td>\n",
       "      <td>135.483765</td>\n",
       "      <td>6826500</td>\n",
       "      <td>Bullish</td>\n",
       "      <td>QCOM</td>\n",
       "      <td>qualcomm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>08-01-2024</td>\n",
       "      <td>136.990005</td>\n",
       "      <td>139.149994</td>\n",
       "      <td>136.639999</td>\n",
       "      <td>139.029999</td>\n",
       "      <td>137.762802</td>\n",
       "      <td>7729400</td>\n",
       "      <td>Bullish</td>\n",
       "      <td>QCOM</td>\n",
       "      <td>qualcomm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date        Open        High         Low       Close   Adj Close  \\\n",
       "0  02-01-2024  142.190002  142.199997  138.779999  140.229996  138.951874   \n",
       "1  03-01-2024  138.889999  138.889999  136.990005  137.600006  136.345856   \n",
       "2  04-01-2024  135.440002  137.330002  134.940002  136.169998  134.928879   \n",
       "3  05-01-2024  136.160004  138.070007  135.850006  136.729996  135.483765   \n",
       "4  08-01-2024  136.990005  139.149994  136.639999  139.029999  137.762802   \n",
       "\n",
       "    Volume Bullish/Bearish ticker company_name  \n",
       "0  8495800         Bearish   QCOM     qualcomm  \n",
       "1  8133300         Bearish   QCOM     qualcomm  \n",
       "2  6770300         Bullish   QCOM     qualcomm  \n",
       "3  6826500         Bullish   QCOM     qualcomm  \n",
       "4  7729400         Bullish   QCOM     qualcomm  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df4 = pd.read_csv('combined_stock_data.csv')\n",
    "df4.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge datasets on date and ticker for final dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### if a date value is missing in df4(i.e. true data) , data of next date is used "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Bullish/Bearish</th>\n",
       "      <th>ticker</th>\n",
       "      <th>company_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>02-01-2024</td>\n",
       "      <td>142.190002</td>\n",
       "      <td>142.199997</td>\n",
       "      <td>138.779999</td>\n",
       "      <td>140.229996</td>\n",
       "      <td>138.951874</td>\n",
       "      <td>8495800</td>\n",
       "      <td>Bearish</td>\n",
       "      <td>QCOM</td>\n",
       "      <td>qualcomm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>03-01-2024</td>\n",
       "      <td>138.889999</td>\n",
       "      <td>138.889999</td>\n",
       "      <td>136.990005</td>\n",
       "      <td>137.600006</td>\n",
       "      <td>136.345856</td>\n",
       "      <td>8133300</td>\n",
       "      <td>Bearish</td>\n",
       "      <td>QCOM</td>\n",
       "      <td>qualcomm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>04-01-2024</td>\n",
       "      <td>135.440002</td>\n",
       "      <td>137.330002</td>\n",
       "      <td>134.940002</td>\n",
       "      <td>136.169998</td>\n",
       "      <td>134.928879</td>\n",
       "      <td>6770300</td>\n",
       "      <td>Bullish</td>\n",
       "      <td>QCOM</td>\n",
       "      <td>qualcomm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>05-01-2024</td>\n",
       "      <td>136.160004</td>\n",
       "      <td>138.070007</td>\n",
       "      <td>135.850006</td>\n",
       "      <td>136.729996</td>\n",
       "      <td>135.483765</td>\n",
       "      <td>6826500</td>\n",
       "      <td>Bullish</td>\n",
       "      <td>QCOM</td>\n",
       "      <td>qualcomm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>08-01-2024</td>\n",
       "      <td>136.990005</td>\n",
       "      <td>139.149994</td>\n",
       "      <td>136.639999</td>\n",
       "      <td>139.029999</td>\n",
       "      <td>137.762802</td>\n",
       "      <td>7729400</td>\n",
       "      <td>Bullish</td>\n",
       "      <td>QCOM</td>\n",
       "      <td>qualcomm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date        Open        High         Low       Close   Adj Close  \\\n",
       "0  02-01-2024  142.190002  142.199997  138.779999  140.229996  138.951874   \n",
       "1  03-01-2024  138.889999  138.889999  136.990005  137.600006  136.345856   \n",
       "2  04-01-2024  135.440002  137.330002  134.940002  136.169998  134.928879   \n",
       "3  05-01-2024  136.160004  138.070007  135.850006  136.729996  135.483765   \n",
       "4  08-01-2024  136.990005  139.149994  136.639999  139.029999  137.762802   \n",
       "\n",
       "    Volume Bullish/Bearish ticker company_name  \n",
       "0  8495800         Bearish   QCOM     qualcomm  \n",
       "1  8133300         Bearish   QCOM     qualcomm  \n",
       "2  6770300         Bullish   QCOM     qualcomm  \n",
       "3  6826500         Bullish   QCOM     qualcomm  \n",
       "4  7729400         Bullish   QCOM     qualcomm  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4 = pd.read_csv('combined_stock_data.csv')\n",
    "df4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ticker        date                                              title  \\\n",
      "0      AXP  03-06-2024  American Express (AXP) Stock Declines While Ma...   \n",
      "1      AXP  04-06-2024  3 Blue-Chip Stocks You'll Regret Not Buying in...   \n",
      "2      AXP  05-06-2024    The 3 Best Blue-Chip Stocks to Buy in June 2024   \n",
      "3      AXP  06-06-2024  Hidden Treasures: 3 Dow Stocks That Deserve MU...   \n",
      "4      AXP  09-06-2024  Baby boomers favorite credit card Amex is now ...   \n",
      "..     ...         ...                                                ...   \n",
      "187   QCOM  25-05-2024  Why Qualcomm Stock Could Still Be a Great Valu...   \n",
      "188   QCOM  26-05-2024  10 Best AI Stocks to Buy for 2024 According to...   \n",
      "189   QCOM  28-05-2024  If You Can Only Buy One Stock in May, It Bette...   \n",
      "190   QCOM  29-05-2024  1 Soaring Artificial Intelligence (AI) Stock t...   \n",
      "191   QCOM  30-05-2024  Is Taiwan Semiconductor (TSM) The Best AI Semi...   \n",
      "\n",
      "    Bullish/Bearish      company_name       Close  \n",
      "0           Bearish  american express  236.880005  \n",
      "1           Bullish  american express  237.250000  \n",
      "2           Bearish  american express  234.690002  \n",
      "3           Bearish  american express  233.350006  \n",
      "4           Bullish  american express  232.440002  \n",
      "..              ...               ...         ...  \n",
      "187         Bearish          qualcomm  213.080002  \n",
      "188         Bearish          qualcomm  213.080002  \n",
      "189         Bearish          qualcomm  213.080002  \n",
      "190         Bearish          qualcomm  208.259995  \n",
      "191         Bearish          qualcomm  204.800003  \n",
      "\n",
      "[192 rows x 6 columns]\n",
      "American Express (AXP) Stock Declines While Market Improves: Some Information for Investors\n"
     ]
    }
   ],
   "source": [
    "df4['Date'] = pd.to_datetime(df4['Date'], format='%d-%m-%Y')\n",
    "df4 = df4.sort_values(by='Date').reset_index(drop=True)\n",
    "\n",
    "\n",
    "df_filtered['date'] = pd.to_datetime(df_filtered['date'], format='%d-%m-%Y')\n",
    "\n",
    "\n",
    "merged_data = []\n",
    "for index, row in df_filtered.iterrows():\n",
    "    ticker = row['ticker']\n",
    "    date = row['date']\n",
    "    \n",
    "    \n",
    "    matching_row = df4[(df4['ticker'] == ticker) & (df4['Date'] == date)]\n",
    "    \n",
    "    if matching_row.empty:\n",
    "        \n",
    "        next_available_row = df4[(df4['ticker'] == ticker) & (df4['Date'] > date)].head(1)\n",
    "        if not next_available_row.empty:\n",
    "            selected_row = next_available_row.iloc[0].copy()\n",
    "            selected_row['Date'] = date  # Keep the original date from df3_grouped\n",
    "        else:\n",
    "            continue  # If no later date is available, skip this row\n",
    "    else:\n",
    "        selected_row = matching_row.iloc[0].copy()\n",
    "        selected_row['Date'] = date  # Keep the original date \n",
    "\n",
    "    \n",
    "    merged_data.append({\n",
    "        'ticker': ticker,\n",
    "        'date': date.strftime('%d-%m-%Y'),\n",
    "        'title': row['title'],\n",
    "        'Bullish/Bearish': selected_row['Bullish/Bearish'],\n",
    "        'company_name': selected_row['company_name'],\n",
    "        'Close' : selected_row['Close']\n",
    "    })\n",
    "\n",
    "\n",
    "df_merged = pd.DataFrame(merged_data)\n",
    "\n",
    "\n",
    "print(df_merged)\n",
    "print(df_merged['title'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ticker        date                                              title  \\\n",
      "0      AXP  03-06-2024  American Express (AXP) Stock Declines While Ma...   \n",
      "1      AXP  04-06-2024  3 Blue-Chip Stocks You'll Regret Not Buying in...   \n",
      "2      AXP  05-06-2024    The 3 Best Blue-Chip Stocks to Buy in June 2024   \n",
      "3      AXP  06-06-2024  Hidden Treasures: 3 Dow Stocks That Deserve MU...   \n",
      "4      AXP  09-06-2024  Baby boomers favorite credit card Amex is now ...   \n",
      "..     ...         ...                                                ...   \n",
      "187   QCOM  25-05-2024  Why Qualcomm Stock Could Still Be a Great Valu...   \n",
      "188   QCOM  26-05-2024  10 Best AI Stocks to Buy for 2024 According to...   \n",
      "189   QCOM  28-05-2024  If You Can Only Buy One Stock in May, It Bette...   \n",
      "190   QCOM  29-05-2024  1 Soaring Artificial Intelligence (AI) Stock t...   \n",
      "191   QCOM  30-05-2024  Is Taiwan Semiconductor (TSM) The Best AI Semi...   \n",
      "\n",
      "    Bullish/Bearish      company_name  compound  \n",
      "0           Bearish  american express    0.4215  \n",
      "1           Bullish  american express   -0.4215  \n",
      "2           Bearish  american express    0.6369  \n",
      "3           Bearish  american express    0.8062  \n",
      "4           Bullish  american express    0.6808  \n",
      "..              ...               ...       ...  \n",
      "187         Bearish          qualcomm    0.7579  \n",
      "188         Bearish          qualcomm    0.6369  \n",
      "189         Bearish          qualcomm    0.4404  \n",
      "190         Bearish          qualcomm    0.7430  \n",
      "191         Bearish          qualcomm    0.6369  \n",
      "\n",
      "[192 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "f = lambda title: vader.polarity_scores(title)['compound']\n",
    "df_merged['compound'] = df_merged['title'].apply(f)\n",
    "\n",
    "print(df_merged)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "df_merged['Bullish/Bearish'] = label_encoder.fit_transform(df_merged['Bullish/Bearish'])\n",
    "\n",
    "\n",
    "X = df_merged['title'].values\n",
    "y = df_merged['Bullish/Bearish'].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tokenizer = Tokenizer(num_words=5000)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "X_train_tokens = tokenizer.texts_to_sequences(X_train)\n",
    "X_test_tokens = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "\n",
    "maxlen = 100\n",
    "X_train_pad = pad_sequences(X_train_tokens, maxlen=maxlen)\n",
    "X_test_pad = pad_sequences(X_test_tokens, maxlen=maxlen)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "4/4 [==============================] - 6s 456ms/step - loss: 0.6960 - accuracy: 0.4098 - val_loss: 0.6944 - val_accuracy: 0.4194\n",
      "Epoch 2/6\n",
      "4/4 [==============================] - 1s 315ms/step - loss: 0.6882 - accuracy: 0.7213 - val_loss: 0.6897 - val_accuracy: 0.6452\n",
      "Epoch 3/6\n",
      "4/4 [==============================] - 1s 311ms/step - loss: 0.6762 - accuracy: 0.6475 - val_loss: 0.6854 - val_accuracy: 0.5806\n",
      "Epoch 4/6\n",
      "4/4 [==============================] - 1s 317ms/step - loss: 0.6587 - accuracy: 0.6066 - val_loss: 0.6765 - val_accuracy: 0.5806\n",
      "Epoch 5/6\n",
      "4/4 [==============================] - 1s 323ms/step - loss: 0.6286 - accuracy: 0.5656 - val_loss: 0.6744 - val_accuracy: 0.5806\n",
      "Epoch 6/6\n",
      "4/4 [==============================] - 1s 314ms/step - loss: 0.5681 - accuracy: 0.6885 - val_loss: 0.6735 - val_accuracy: 0.6129\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=5000, output_dim=128, input_length=maxlen))   ## keras embeddings are tasks specific \n",
    "## whereas word2vec embeddings are general in nature \n",
    "model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "history = model.fit(X_train_pad, y_train, epochs=6, batch_size=32, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 - 0s - loss: 0.6263 - accuracy: 0.7179 - 236ms/epoch - 118ms/step\n",
      "Accuracy: 0.7179487347602844\n",
      "2/2 [==============================] - 1s 95ms/step\n",
      "Accuracy: 0.717948717948718\n"
     ]
    }
   ],
   "source": [
    "\n",
    "loss, accuracy = model.evaluate(X_test_pad, y_test, verbose=2)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "\n",
    "\n",
    "y_pred = (model.predict(X_test_pad) > 0.5).astype(\"int32\")\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(f'Accuracy: {accuracy_score(y_test, y_pred)}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
